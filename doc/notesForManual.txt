Timer: Is also resolution for delay and waitForEvent. If run-time optimal
(tic=fastest task time) than the fastest task has no chance to use other
delay than with limit to next regular task due time

Event ISRs (incl. system time tic generation): Always need to save
complete context as it normally triggers a context switch. By machine code
it could be approriate to save it conditionally and in parts if the ISR
does some preparatory work and triggers an event only under conditions,
which itself defines. E.g. a keyboard read routine, which reports a key
touched event only after doing some debouncing in a series of ISR
invokations (state machine). Only if the event is set, all other registers
(which are not used by the ISR itself) are saved, before the event setting
API function of the RTOS is invoked.

The context switch may enable global interrupts first to not block high
priority interrupts. How to do and rules: Those ISRs must not trigger an
event which could result in a context switch (otherwise danger of stack
overflow in case of many sub-sequent task switches - but is it really if
2ms timer is only source of undetermined task switch?). Possible e.g. for
I/O handling with high responsiveness. Initialization and feedback can
only be done in a normal task not using the RTOS events.
  Double check if timer0 used by Arduino for millis etc. is an example.

The matter "when to disable/enable IRQ" should become an own topic in the
manual.

Explain cli/sei versus enterLeaveCriticalSection: All interrupts are
locked or only the task switch causing one.

Tasks can be interrupted only by tasks of higher priority. If round robin
is implemented and activated, it may also be interrupted by tasks of same
priority class. Those and only those tasks which share data with tasks
which may interrupt them because of the rules before, need to apply calls
of enter/leaveCriticalSection to protect the access to this data.

Enter/leaveCriticalSection is part of the code adaptations when binding a
new interrupt to an existing event. ECS/LCS need to lock all interrupts
which possibly can cause a task switch - but no other interrupts.
  Example: producer-consumer model ADC: Free-running mode, interrupt on
conversion completed sets event. Task waiting for event with high priority
will read the result and switch the channel. It'll than do the
anti-aliasing filtering. The time-triggered slow task reads the filter
output (and does implicitly do the downsampling this way).

Idle task may set an event but may not suspend in any way. If it sets an
event it can be sure that the awaked task has completed all related data
processing until idle gets reactivated again. Therefore, a
producer-consumer solution can be implemented with a single event as
access synchronization, no ECS/LCS needs to be applied. (Explain why and
generalize this idea to any pair of tasks of different priority classes.)

Compiler assumptions/prerequisites:
  naked, no prologue
  no local data in stack frame
  parameters in registers, without using stack frame: Problem with .O0 (http://lists.gnu.org/archive/html/avr-gcc-list/2012-08/msg00014.html)
  r24/r25 for return value 

Look for comment blocks in source code.

    Idea: A task needs to return a value at restore context when and only when it is
    activated the very first time after it had been suspended. (It will not return a value
    if it is activated from an interruption by another task of higher priority or because
    of a round-robin cycle.) Prove: The
    task gets suspended only on its own demand by calling one of the suspend functions
    and these functions have a return value. (Exception is task initialization: if we set
    r24/25 now, it'll become the function parameter. This inhibits a general purpose
    parameter but generalizes the start of a task: It can be started by any combination of
    events and its parameter tells how it actually was.)
      Thus: The activation will check the event vector. If not null the task is awaked,
    thus activated the first time after suspension. Now the event vector is returned and
    reset in the task array. If we find event vector equal to null, the task is activated
    for continuation, not after a suspend, and the completed pushed context is restored.
      In the first case, we will overwrite r24/25 with the return value and this can be
    done easiest by pushing the values after switching the SP and then doing a complete pop
    context. (Required change: r24/25 is the topmost entry in the pushed context.)
    Consequently, the switch functions and the task stack preparation would not push r24/25
    as part of the context.
      Going back to a context:
    If task ID stays same: do not switch SP, pop all, reti.
    If task ID changes:
        If eventVec of new task is null
            Switch SP, pop all, reti
        If eventVec of new task is not null
            Switch SP, push eventVec, clear eventVec, pop all, reti

Why do we not have type eventMask_t and leave it to the user if he needs
8, 16 or 32 events? The complexity of stack handling for passing the event
mask parameters hence and force would require quite complex #if switches
which would make the code ugly. It's however basically possible without
conceptual changes.

Explain the flag-meaning of task.postedEventVec, how it tracks from which
state a task comes from and how it determines what the return in r24/25 to
the caller

Producer-Consumer patterns like
taskProducer()
{
    while(rtos_waitForEvent(myEvtStartToProduce))
    {
        /* Generate the shared, produced data. */
        ...

        /* Signal "data available". */
        rtos_setEvent(myEvtStartToConsume);
    }
}
taskConsumer()
{
    while(rtos_waitForEvent(myEvtStartToComsume))
    {
        /* Evaluate the shared, produced data. */
        ...

        /* Signal termination. */
        rtos_setEvent(myEvtStartToProduce);
    }
}
will run only if both tasks have same priority and no round robin characteristics.
Otherwise we'd need an atomic combination of setting events and suspending with waiting for
other events. If the consumer had e.g. a higher priority as the producer, it could be
started in the instance the producer posts the event "data available". When it would post
the event "start next production cycle", this event would be lost as the producer is not
yet listening to this event. At this time the producer's program counter still points into
the middle of its setEvent method - the lower priority task had no chance to reach the call
of rtos_waitForEvent yet.

In practice we often have a loose coupling between consumer and producer. Consuming the
data is considered fast in comparison to the production cycle and backward feedback is not
implemented. Principally, data can be lost but the probability is low enough to neglect
this risk. An example can be an interrupt driven I/O operation. Each time the ADC has
completed a conversion is sets an event and a task of high priority reads the data and
processes it:
taskReadADC()
{
    while(rtos_waitForEvent(myEvtADCConversionReady))
    {
        /* The ADC is read and retriggered for the next conversion. */
        x = readADC();
        
        /* The read value is low pass filtered and put into a global variable from where it
           is processed by another, slower, regular task. The slower task is of lower
           priority, therefore we need no mutex operation here in this task. */
        globalY = antiAliasFilter(x);
    }        
}

DEBUG compilation and particularly ASSERT requires initialization of Serial

Potential to optimize: Less memory by compact arrays, pointers to vectors
of individual size (if classes contain strongly differing numbers of
tasks)
  Idle task object only uses three fields. Consider to pack these into
separate struct and have this n+1 time whereas the rest is used only n
times.

makefile: Switch of application/TC always requires a clean as the
configuration of rtos.c (no tasks) differs